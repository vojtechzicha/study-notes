<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
    <title>Statistika I / Statistika A - Studijní poznámky</title>

    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.css"
      integrity="sha384-5TcZemv2l/9On385z///+d7MSYlvIEw9FuZTIdZ14vJLqWphw7e7ZPuOiCHJcFCP"
      crossorigin="anonymous"
    />

    <!-- The loading of KaTeX is deferred to speed up page rendering -->
    <script
      defer
      src="https://cdn.jsdelivr.net/npm/katex@0.16.22/dist/katex.min.js"
      integrity="sha384-cMkvdD8LoxVzGF/RPUKAcvmm49FQ0oxwDF3BGKtDXcEc+T1b2N+teh/OJfpU0jr6"
      crossorigin="anonymous"
    ></script>

    <!-- Load our local stylesheet and custom loader script -->
    <link rel="stylesheet" href="styles.css" />
    <script defer src="katex-loader.js"></script>
  </head>
  <body>
    <header class="main-header">
      <div class="header-content">
        <a href="index.html" class="back-button">← Zpět</a>
        <a href="index.html" class="home-link">Univerzitní studium</a>
        <!-- THIS IS THE NEW BREADCRUMB LOGIC -->
        <span class="breadcrumb-item">Fakulta elektrotechniky a
informatiky VŠB-TU Ostrava (bakalářský)</span>
        <span class="breadcrumb-separator">›</span>
        <span class="breadcrumb-item-active">Statistika I / Statistika
A</span>
      </div>
    </header>

    <div class="page-container">
      <main class="content">
        <header id="title-block-header">
          <h1 class="title">Statistika I / Statistika A</h1>
        </header>
        <p>Vytvořeno na základě materiálů prof. Ing. Radima Briše, CSc.
        pro předmět <strong>AM2401 Statistika I</strong>. Učivo
        rozšířeno z materiálů RNDr. Anny Madryové, Ph.D. pro předmět
        <strong>MM0403 Statistika A</strong> v kombinované formě.</p>
        <h1 id="explorační-analýza-dat">Explorační analýza dat</h1>
        <p>Data představují výsledky <strong>datově generačního
        procesu</strong> – z množiny měřených objektů (domain) vybíráme
        proměnné měřených veličin. Množina měřených hodnot musí být
        vyčerpávající a vzájemně vylučující. Data vybírám z několika
        charakteristických typů:</p>
        <ul>
        <li><p><strong>Kvalitativní proměnná</strong> – nabývá z předem
        daných hodnot, dělíme na <strong>nominální</strong> (má smysl
        hodnotu dané kategorie pojmenovat, k popisu slouží
        <strong>četnost</strong> proměnné) a <strong>ordinální</strong>
        (má smysl pořadí hodnoty dané kategorie). Dále se dělí na
        <strong>alternativní</strong> (vlastnosti, atributy, nabývají
        jedné ze dvou hodnot) nebo <strong>množné</strong>.</p></li>
        <li><p><strong>Kvantitativní proměnná</strong> – nabývá hodnoty
        z množiny <span class="math inline">\mathbb{R}</span>. Mohou být
        <strong>diskrétní</strong> (nabývají diskrétních hodnot
        v <strong>konečné</strong>m počtu nebo
        <strong>spočtené</strong>m počtu) nebo
        <strong>spojité</strong>.</p></li>
        </ul>
        <p>Nominální kvalitativní proměnná nabývají absolutní četnosti
        <span class="math inline">n_{i}</span>, přičemž platí <span
        class="math inline">\sum_{}^{}n_{i} = n</span>. Relativní
        četnost <span class="math inline">p_{i} =
        \frac{n_{i}}{n}</span>, přičemž <span
        class="math inline">\sum_{}^{}p_{i} = 1</span>. Definujeme
        <strong>modus</strong> jako název varianty proměnné vykazující
        nejvyšší četnost. <strong>Histogram</strong> je klasickým
        grafem, v němž na jednu osu vynášíme varianty a na druhou jejich
        četnost. <strong>Výsečový graf</strong> prezentuje relativní
        četnosti jednotlivých variant pomocí plochami kruhových
        výsečí.</p>
        <p>Ordinální kvalitativní proměnná využívá pro popis stejné
        charakteristiky jako pro popis nominální proměnné.
        <strong>Kumulativní četnost</strong> <span
        class="math inline">m_{i}</span> definujeme jako počet hodnot
        proměnné, které nabývají varianty nižší nebo rovné dané
        variantě. Pokud <span class="math inline">x_{1} &lt; \ldots &lt;
        x_{n}</span>, platí <span class="math inline">m_{i} = \sum_{j =
        1}^{i}n_{j}</span>. <strong>Kumulativní relativní
        četnost</strong> <span class="math inline">F_{i} =
        \frac{m_{i}}{n}</span>. <strong>Polygon kumulativních
        četností</strong> je spojnicovým grafem, v němž se na vodorovnou
        osu vynáší jednotlivé varianty v pořadí od „nejmenší“ do
        „největší“ a na svislou osu nanášíme kumulativní četnosti.
        <strong>Paretův graf</strong> je často užívaným grafem spojením
        histogramu a polygonu kumulativních četností, v němž na
        vodorovnou osu vynášíme v pořadí od „největšího významu“ po
        „nejmenší význam“.</p>
        <p>Kvantitativní proměnné využívá stejné charakteristiky jako
        pro popis ordinální proměnné. Definujeme <em>míry polohy</em>
        určující typické rozložení hodnot proměnné a <em>míry
        variability</em> určující variabilitu hodnot kolem své typické
        polohy. <strong>Aritmetický průměr</strong> je mírou polohy
        <span class="math inline">\overline{x} =
        \frac{\sum_{}^{}x_{i}}{n}</span>. <strong>Modus pro diskrétní
        proměnnou</strong> jako hodnotu nejčastější varianty proměnné.
        <strong>Modus pro spojité proměnné</strong> považujeme za modus
        hodnotu, kolem níž je největší koncentrace hodnot proměnné. Pro
        určení hodnoty využijeme <strong>shorth</strong>, což je
        nejkratší interval, v němž leží alespoň 50 % hodnot proměnné.
        Modus <span class="math inline">\widehat{x}</span> definujeme
        jako střed shorthu.</p>
        <p><strong>Kvantily</strong> <span
        class="math inline">x_{p}</span> jsou statistiky, které
        charakterizují polohu jednotlivých hodnot v rámci proměnné.
        Rozdělují datový soubor na dvě části - <span
        class="math inline">100p</span>% a zbytek</p>
        <ul>
        <li><p><strong>Dolní kvartil</strong> <span
        class="math inline">x_{0.25}</span> rozděluje datový soubor tak,
        že 25 % hodnot je menších než tento kvartil a zbytek, tj. 75 %
        větších nebo rovných.</p></li>
        <li><p><strong>Medián</strong> <span
        class="math inline">x_{0.5}</span> rozděluje datový soubor tak,
        že 50 % hodnot je menších než medián a zbytek, tj. 50 % větších
        nebo rovných.</p></li>
        <li><p><strong>Horní kvartil</strong> <span
        class="math inline">x_{0.75}</span> rozděluje datový soubor tak,
        že 75 % hodnot je menších než tento kvartil a zbytek, tj. 25 %
        větších nebo rovných.</p></li>
        <li><p><strong>Decily</strong> rozdělují výběrový soubor na 10
        stejně četných částí.</p></li>
        <li><p><strong>Percentily</strong> dělí výběrový soubor na 100
        stejně četných částí.</p></li>
        </ul>
        <p>Lze říci, že hodnota <span class="math inline">p</span> udává
        kumulativní relativní četnost kvantilu <span
        class="math inline">x_{p}</span>. Kvantil a kumulativní
        relativní četnost jsou tedy inverzní hodnoty.</p>
        <p><strong>Empirická distribuční funkce</strong> <span
        class="math inline">\mathbf{F}\left( \mathbf{x} \right)</span>
        <strong>pro kvantitativní proměnnou</strong> – označme si <span
        class="math inline">p\left( x_{i} \right)</span> relativní
        četnost hodnoty <span class="math inline">x_{i}</span>. Poté
        platí, že <span class="math inline">F(x) = \sum_{}^{}{p\left(
        x_{i} \right)}</span>. <strong>Interkvalitové rozpětí
        IQR</strong> je mírou variability souboru a je definována jako
        vzdálenost mezi horním a dolním kvartilem <span
        class="math inline">IQR = \ x_{0.75} - x_{0.25}</span>.
        <strong>Median Absolute Deviation</strong> <strong>from
        median</strong> (MAD) jakožto charakteristikou
        rozptýlenosti.</p>
        <ol type="1">
        <li><p>Výběrový soubor uspořádáme podle velikosti.</p></li>
        <li><p>Určíme medián souboru <span
        class="math inline">x_{0.5}</span>.</p></li>
        <li><p>Pro každou hodnotu souboru určíme absolutní hodnotu její
        odchylky od mediánu <span class="math inline">\left| y_{i} -
        x_{0.5} \right|</span>.</p></li>
        <li><p>Absolutní odchylky od mediánu uspořádáme podle
        velikosti.</p></li>
        <li><p>Určíme medián absolutních odchylek od mediánu, tj.
        MAD.</p></li>
        </ol>
        <p>Mezi charakteristiky rozptýlenosti patří dále
        <strong>výběrový rozptyl</strong> <span
        class="math inline">s^{2} = \frac{{\sum_{}^{}\left( x_{i} -
        \overline{x} \right)}^{2}}{n - 1}</span> a <strong>směrodatná
        odchylka</strong> <span class="math inline">s =
        \sqrt{s^{2}}</span>. Odlehlou hodnotou <strong>outlier</strong>
        nazýváme hodnotu, která svou charakteristikou nepatří do
        datového souboru. Existují tři detekce outlier hodnot:</p>
        <ol type="1">
        <li><p>Za odlehlé pozorování lze považovat takovou hodnotu,
        jejíž absolutní hodnota <strong>z-souřadnice</strong> je větší
        než 3: <span class="math inline">z_{i} = \frac{x_{i} -
        \overline{x}}{s}</span>. Z-souřadnici můžeme interpretovat jako
        počet směrodatných odchylek, o kolik se hodnota liší od
        průměru.</p></li>
        <li><p>Za odlehlé pozorování lze považovat takovou hodnotu,
        jejíž absolutní hodnota <strong>mediánové souřadnice</strong> je
        větší než 3: <span class="math inline">m_{i} = \frac{x_{i} -
        x_{0.5}}{1.483 \cdot MAD}</span>. Mediánová metoda je vhodnější
        než z-souřadnice díky menší závislosti na okrajových
        hodnotách.</p></li>
        </ol>
        <p>Definujme čísla se specifickým významem: <span
        class="math inline">\mathbf{k}</span><strong>-tý obecný výběrový
        moment</strong> definujeme jako <span
        class="math inline">m_{k}&#39; = \frac{1}{n}\sum_{}^{}\left(
        x_{i} \right)^{k},m_{0}&#39; = 1,m_{1}&#39; =
        \overline{x}</span> a <span
        class="math inline">\mathbf{k}</span><strong>-tý centrální
        výběrový moment</strong> definujeme jako <span
        class="math inline">m_{k} = \frac{1}{n}\sum_{}^{}\left( x_{i} -
        \overline{x} \right)^{k},m_{0} = 1,m_{1} = 0,m_{2} = s_{0}^{2} =
        \frac{1}{n}\sum_{}^{}\left( x_{i} - \overline{x}
        \right)^{2}</span>. <strong>Výběrová šikmost</strong> vyjadřuje
        asymetrii rozložení hodnot kolem jejího průměru <span
        class="math inline">\alpha = \frac{m_{3}}{s_{0}^{3}} =
        \frac{1}{n \cdot s^{3}} \cdot \sum_{}^{}\left( x_{i} -
        \overline{x} \right)^{3}</span>. Interpretujme: pokud <span
        class="math inline">\alpha = 0</span>, tak jsou hodnoty proměnné
        kolem jejího průměru rozloženy symetricky; pokud <span
        class="math inline">\alpha &gt; 0</span>, tak u proměnné
        převažují hodnoty menší než průměr a pokud <span
        class="math inline">\alpha &lt; 0</span>, tak u proměnné
        převažují hodnoty větší než průměr. <strong>Výběrová
        špičatost</strong> <span class="math inline">\beta =
        \frac{m_{4}}{s_{0}^{4}} - 3 = \frac{1}{n} \cdot
        \frac{\sum_{}^{}\left( x_{i} - \overline{x} \right)^{4}}{s^{4}}
        - 3</span> vyjadřuje podobnost rozdělení k normálnímu rozdělení.
        Interpretujme: pokud <span class="math inline">\beta = 0</span>,
        tak špičatost odpovídá normálnímu rozdělení; pokud <span
        class="math inline">\beta &gt; 0</span>, tak je proměnná
        rozdělena špičatě a pokud <span class="math inline">\beta &lt;
        0</span>, tak je proměnná rozdělena plošně.</p>
        <p><img
        src="fakulta-elektrotechniky-a-informatiky-vsb-tu-ostrava-bakalarsky-am2401-statistika-i_media/media/image1.tmp"
        style="width:2.0814in;height:1.33721in" />Kvalitativní proměnné
        vizualizujeme pomocí <strong>box-and-whiskers</strong> grafu,
        který reprezentuje minimum, dolní kvartil, medián, horní kvartil
        a maximum. Často se využívá s <strong>histogramem
        četnosti</strong> dělící datový soubor na třídy stejné délky a
        různé četnosti. <strong>Číslicový histogram</strong>
        (<strong>steam and leaf plot</strong>) dělí datový soubor na
        třídy stejné délky, v rámci každé třídy na lodyze máme listy
        určující jednotlivé položky v dané třídě.</p>
        <h1 id="teorie-pravděpodobnosti">Teorie pravděpodobnosti</h1>
        <p><strong>Pokus</strong> je konečný děj, který probíhá při
        určitém souboru fyzikálních podmínek. <strong>Náhodný
        pokus</strong> je takový pokus, jehož výsledek je náhodný při
        konstantních podmínkách. <strong>Hromadný pokus</strong> je
        pokus, který můžeme libovolněkrát opakovat při konstantních
        podmínkách. Výsledky pokusů musí být neslučitelné (k dvěma
        různým výsledkům nemůže dojít současně) a vyčerpávající (k
        nějakému výsledku dojít musí) – množinu všech výsledků nazýváme
        <span class="math inline">\Omega \neq \varnothing</span>
        <strong>základní prostor</strong>. Jednoprvkové podmnožiny <span
        class="math inline">\omega \subset \Omega</span> nazýváme
        <strong>elementární jev</strong>. Libovolné podmnožiny <span
        class="math inline">A \subset \Omega</span> nazýváme
        <strong>jevy</strong>. <strong>Jev nemožný</strong> <span
        class="math inline">\varnothing</span> nemůže nastat za žádných
        okolností. <strong>Jev jistý</strong> <span
        class="math inline">\Omega</span> nastane při každé realizaci
        náhodného pokusu.</p>
        <p><strong>Jevové pole</strong> <span
        class="math inline">\mathcal{S}</span> je systém podmnožin, pro
        který platí <span class="math inline">A \in \mathcal{S
        \Rightarrow}\overline{A}\mathcal{\in S}</span> (systém je
        uzavřený vůči svým doplňkům) a <span class="math inline">\left(
        A_{1},\ldots \right),A_{i}\mathcal{\in S
        \Rightarrow}\bigcup_{}^{}A_{i}\mathcal{\in S}</span>. Elementy
        jevového pole nazýváme <strong>náhodnými</strong> jevy.
        Uspořádaná trojice <span
        class="math inline">(\Omega\mathcal{,S,}P)</span> tvoří
        <strong>pravděpodobnostní prostor</strong> náhodného pokus, kde
        <strong>pravděpodobnostní funkce</strong> <span
        class="math inline">\mathbf{P}\mathcal{:S}\mathbb{\rightarrow
        R}</span> splňuje <span class="math inline">A \in
        \mathcal{S:}P(A) \geq 0</span>, <span
        class="math inline">P(\Omega) = 0</span> a <span
        class="math inline">\left( A_{1},.. \right),A_{i}\mathcal{\in
        S,}A_{i} \cap A_{j} = \varnothing:P\left( \bigcup_{}^{}A_{i}
        \right) = \sum_{}^{}{P\left( A_{i} \right)}</span> (tzv.
        sigmaaditivita).</p>
        <ul>
        <li><p><span class="math inline">A,B \in \mathcal{S,}A \subset B
        \Rightarrow P(A) \leq P(B)</span></p></li>
        <li><p><span class="math inline">P\left( \overline{A} \right) =
        1 - P(A)</span></p></li>
        <li><p><span class="math inline">P(A - B) = P(A) - P(A \cap
        B)</span></p></li>
        <li><p><span class="math inline">P(A \cup B) = P(A) + P(B) - P(A
        \cap B)</span></p></li>
        </ul>
        <p><strong>Podmíněná pravděpodobnost</strong> značí vztah <span
        class="math inline">P\left( A \middle| B \right) = \frac{P(A
        \cap B)}{P(B)},P(B) \neq 0</span>. Jevy jsou
        <strong>nezávislé</strong>, pokud <span
        class="math inline">P\left( A \middle| B \right) = P(A)</span>
        nebo <span class="math inline">P(B) = 0</span>. Pro nezávislé
        jevy platí <span class="math inline">P(A \cap B) = P(A) \cdot
        P(B)</span>. Jevy <span
        class="math inline">A_{1},\ldots,A_{n}</span> jsou
        <strong>stochasticky nezávislé</strong> právě tehdy, když <span
        class="math inline">P\left( \bigcap_{}^{}A_{i} \right) =
        \prod_{}^{}{P\left( A_{i} \right)}</span>.</p>
        <p>Pro úplnou skupinu disjunktních jevů <span
        class="math inline">B_{1},..,B_{n},B_{i} \cup B_{j} =
        \varnothing</span> vyslovme <strong>Total Probability
        Theorem</strong>: <span class="math inline">A \in
        \mathcal{S,}P(A) = \sum_{}^{}{P\left( A \middle| B_{i} \right)
        \cdot P\left( B_{i} \right)} = \sum_{}^{}{P\left( A \cap B_{i}
        \right)}</span> a <strong>Bayes Theorem:</strong> <span
        class="math inline">P\left( B_{k} \middle| A \right) =
        \frac{P\left( A \middle| B_{k} \right) \cdot P\left( B_{k}
        \right)}{\sum_{}^{}{P\left( A \middle| B_{i} \right) \cdot
        P\left( B_{i} \right)}}</span>.</p>
        <h1 id="náhodná-veličina">Náhodná veličina</h1>
        <p>Mějme pravděpodobnostní prostor <span
        class="math inline">(\Omega,S,P)</span>. <strong>Náhodná
        veličina</strong> <span class="math inline">X</span> je reálná
        funkce prvků <span class="math inline">\omega \in \Omega</span>
        ze základního prostoru taková, že pro každé reálné <span
        class="math inline">x\mathbb{\in R}</span> je množina <span
        class="math inline">\left\{ \omega \in \Omega \middle| X(\omega
        &lt; x) \right\} \in S</span>, tj. náhodným jevem. Náhodná
        veličina je zobrazením <span
        class="math inline">X:\Omega\mathbb{\rightarrow R}</span>
        takové, že pro každé <span class="math inline">x \in R</span>
        platí <span class="math inline">X\left( ( - \infty,x) \right) =
        \left\{ \omega \in \Omega \middle| X(\omega &lt; x) \right\} \in
        S</span>. Množina <span class="math inline">\{ x =
        X(\omega),\omega \in \Omega\}</span> se nazývá <strong>základní
        soubor</strong>.</p>
        <p>Nechť <span class="math inline">X</span> je náhodná veličina.
        Reálnou funkci <span class="math inline">F(t)</span> definovanou
        pro všechna reálná <span class="math inline">t\mathbb{\in
        R}</span> vztahem</p>
        <p><span class="math display">F(t) = P\left\{ X \in ( -
        \infty,t) \right\} = P(X &lt; t)</span></p>
        <p>Nazveme <strong>distribuční funkcí</strong> náhodné veličiny
        <span class="math inline">X</span>. Jedná se tedy o funkci,
        která každému reálnému číslu přiřazuje pravděpodobnost, že
        náhodná veličina nabude hodnoty menší než toto reálné číslo.</p>
        <ol type="1">
        <li><p>Distribuční funkce je <u>nezáporné číslo menší nebo rovno
        jedné</u>.<br />
        <span class="math display">0 \leq F(x) \leq 1</span></p></li>
        <li><p>Distribuční funkce je <u>neklesající</u>.<br />
        <span class="math display">\forall x_{1},x_{2}\mathbb{\in
        R:}x_{1} &lt; x_{2} \Rightarrow F\left( x_{1} \right) \leq
        F\left( x_{2} \right)</span></p></li>
        <li><p>Distribuční funkce je <u>zleva spojitá</u>.</p></li>
        <li><p><span class="math inline">\lim_{x \rightarrow
        \infty}{F(x)} = 1</span>, <span class="math inline">\lim_{x
        \rightarrow - \infty}{F(x)} = 0</span></p></li>
        <li><p><span class="math inline">\forall a,b\mathbb{\in R,}a
        &lt; b:P(a \leq X &lt; b) = F(b) - F(a)</span></p></li>
        <li><p><span class="math inline">P\left( x = x_{0} \right) =
        \lim_{x \rightarrow x_{0}^{+}}{F(x) - F\left( x_{0}
        \right)}</span></p></li>
        </ol>
        <p>Pro <strong>diskrétní náhodnou veličinu</strong> platí, že
        existuje konečná nebo spočetná množina reálných čísel <span
        class="math inline">M = \{ x_{1},\ldots,x_{n},\ldots\}</span>
        takových, že <span class="math inline">P\left( X = x_{i} \right)
        &gt; 0,i = 1,\ldots,n,\ldots</span> a <span
        class="math inline">\sum_{}^{}{P\left( X = x_{i} \right)} =
        1</span>. Funkce <span class="math inline">P\left( x_{i} \right)
        = P(X = x_{i})</span> se nazývá <strong>pravděpodobnostní
        funkcí</strong> náhodné veličiny <span
        class="math inline">X</span>. Distribuční funkce je schodovitá a
        platí pro ni <span class="math inline">F(x) = \sum_{x_{i} &lt;
        x}^{}{P(X = x_{i})}</span>.</p>
        <p>Pro <strong>spojitou náhodnou veličinu</strong> platí, že
        distribuční funkce má tvar <span class="math inline">F(x) =
        \int_{- \infty}^{x}{f(t)dt}</span>, kde <span
        class="math inline">f(x)</span> je nezáporná funkce zvaná
        <strong>hustota pravděpodobnosti</strong>, pro kterou platí, že
        <span class="math inline">\int_{- \infty}^{\infty}{f(x)dx} =
        1</span>. Ve všech bodech, kde existuje derivace distribuční
        funkce platí <span class="math inline">f(x) =
        \frac{dF(x)}{dx}</span>. Platí, že</p>
        <ol type="1">
        <li><p><span class="math inline">P(X &lt; a) = F(a) = \int_{-
        \infty}^{a}{f(x)dx}</span></p></li>
        <li><p><span class="math inline">P(X \geq a) = 1 - F(a) =
        \int_{a}^{\infty}{f(x)dx}</span></p></li>
        <li><p><span class="math inline">P(a \leq X &lt; b) = F(b) -
        F(a) = \int_{a}^{b}{f(x)dx}</span></p></li>
        <li><p><span class="math inline">P(X = x) = 0</span></p></li>
        </ol>
        <p>Dvě náhodné veličiny <span class="math inline">X,Y</span>
        jsou <strong>nezávislé</strong>, pokud pro náhodný vektor (viz
        Náhodný vektor) <span class="math inline">A = (X,Y)</span> platí
        <span class="math inline">F(x,y) = F_{x}(x) \cdot
        F_{y}(y)</span>.</p>
        <h2 id="číselné-charakteristiky-náhodné-veličiny">Číselné
        charakteristiky náhodné veličiny</h2>
        <p><u>Obecný moment</u> <span
        class="math inline">r</span><u>-tého řádu</u> <span
        class="math inline">\mu_{r}&#39; = EX^{r} = \int_{-
        \infty}^{\infty}{x^{r}f(x)dx}</span>.</p>
        <p><u>Centrální moment</u> <span
        class="math inline">r</span><u>-tého řádu</u> <span
        class="math inline">\mu_{r} = E(X - EX)^{r} = \int_{-
        \infty}^{\infty}{(x - EX)^{r}f(x)dx}</span>.</p>
        <p><u>Střední hodnota</u> <span class="math inline">EX = \mu =
        \int_{- \infty}^{\infty}{xf(x)dx}</span></p>
        <ul>
        <li><p><span class="math inline">E(aX + b) = aEX +
        b</span></p></li>
        <li><p><span class="math inline">E\left( X_{1} + X_{2} \right) =
        EX_{1} + EX_{2}</span></p></li>
        <li><p><span class="math inline">E\left( X_{1}X_{2} \right) =
        E\left( X_{1} \right)E(X_{2})</span> pro nezávislé náhodné
        veličiny</p></li>
        <li><p><span class="math inline">Y = g(X) \Rightarrow EY =
        E\left( g(X) \right) = \int_{-
        \infty}^{\infty}{g(x)f(x)dx}</span></p></li>
        </ul>
        <p><u>Rozptyl</u> <span class="math inline">DX = \mu_{2} = E(X -
        EX)^{2} = EX^{2} - (EX)^{2} = \int_{-
        \infty}^{\infty}{x^{2}f(x)dx} - \left( \int_{-
        \infty}^{\infty}{xf(x)dx} \right)^{2}</span>.</p>
        <ul>
        <li><p><span class="math inline">D(aX + b) =
        a^{2}DX</span></p></li>
        <li><p><span class="math inline">D\left( X_{1} + X_{2} \right) =
        DX_{1} + DX_{2}</span> pro nezávislé náhodné veličiny</p></li>
        </ul>
        <p><u>Směrodatná odchylka</u> <span
        class="math inline">\sigma_{x} = \sqrt{DX}</span></p>
        <p><u>Šikmost</u> (<em>skewness</em>) – mírou symetrie daného
        rozdělení <span class="math inline">a_{3} =
        \frac{\mu_{3}}{\sigma_{x}^{3}}</span> (<span
        class="math inline">a_{3} = 0</span> symetrický soubor, <span
        class="math inline">a_{3} &lt; 0</span> negativně zešikmený
        soubor, <span class="math inline">a_{3} &gt; 0</span> pozitivně
        zešikmený soubor).</p>
        <p>Špičatost (<em>kurtosis</em>) – míra plochosti/špičatosti
        <span class="math inline">a_{4} =
        \frac{\mu_{4}}{\sigma_{x}^{4}}</span> (<span
        class="math inline">a_{4} &lt; 3</span> plošší, <span
        class="math inline">a_{4} &gt; 3</span> špičatější).</p>
        <p><u>Kvantily</u> jsou definovány jako v Explorační analýza dat
        <span class="math inline">F\left( x_{p} \right) = p</span>.</p>
        <p><u>Modus</u> <span class="math inline">\widehat{x}</span> je
        pro diskrétní NV hodnota <span class="math inline">P\left( X =
        \widehat{x} \right) \geq P\left( X = x_{i} \right)</span>, pro
        spojitou NV <span class="math inline">f\left( \widehat{x}
        \right) \geq f(x)</span>.</p>
        <h1 id="náhodný-vektor">Náhodný vektor</h1>
        <p><strong>Náhodným vektorem</strong> rozumíme sloupcový vektor
        složený z náhodných veličin <span class="math inline">\mathbf{X}
        = \left( X_{1},X_{2},\ldots,X_{n} \right)</span>.
        <strong>Sdružená distribuční funkce</strong> náhodných veličin
        <span class="math inline">F\left( x_{1},..,x_{2} \right) =
        P\left( X_{1} &lt; x_{1},\ldots,X_{n} &lt; x_{n}
        \right)</span>.</p>
        <ul>
        <li><p><span class="math inline">\lim_{\mathbf{x} \rightarrow -
        \infty}{F(\mathbf{x})} = 0</span></p></li>
        <li><p><span class="math inline">\lim_{\mathbf{x} \rightarrow
        \infty}{F(\mathbf{x})} = 1</span></p></li>
        <li><p>Funkce je neklesající a zleva spojitá v každé
        proměnné</p></li>
        <li><p><span class="math inline">P\left( a_{1} \leq X_{1} &lt;
        b_{1},a_{2} \leq Y &lt; b_{2} \right) = F\left( b_{1},b_{2}
        \right) - F\left( b_{1},a_{2} \right) - F\left( a_{1},b_{2}
        \right) + F(a_{1},a_{2})</span></p></li>
        </ul>
        <p>V případě <strong>náhodného vektoru s diskrétním
        rozdělením</strong> definujeme sdruženou distribuční funkci jako
        <span class="math inline">F\left( x_{1},\ldots,x_{n} \right) =
        \sum_{x_{1i} &lt; x_{1},\ldots,x_{ni} &lt; x_{n}}^{}{P(X_{1} =
        x_{1i},\ldots,X_{n} = x_{ni})}</span>, kde <span
        class="math inline">P(x_{1i},\ldots,x_{ni})</span> je
        <strong>sdružená pravděpodobnostní funkce</strong>. V případě
        <strong>náhodného vektoru se spojitým rozdělením</strong> platí
        běžné definice rozložené do více dimenzí.</p>
        <p><img
        src="fakulta-elektrotechniky-a-informatiky-vsb-tu-ostrava-bakalarsky-am2401-statistika-i_media/media/image2.tmp"
        style="width:5.24514in;height:1.96181in" />Chceme-li určit
        distribuční funkci veličiny <span class="math inline">X</span>
        z dvousložkového vektoru, mluvíme o <strong>marginální
        distribuční funkci</strong> <span class="math inline">F_{x}(x) =
        P(X &lt; x) = \lim_{y \rightarrow \infty}{F(x,y)}</span>, <span
        class="math inline">F_{y}(Y) = P(Y &lt; y) = \lim_{x \rightarrow
        \infty}{F(x,y)}</span>.</p>
        <p>Chceme-li určit hustotu pravděpodobnosti veličiny <span
        class="math inline">X</span> z dvousložkového vektoru, mluvíme o
        <strong>marginální hustotě pravděpodobnosti</strong> <span
        class="math inline">f_{x}(x) = \int_{y \rightarrow
        \infty}^{}{F(x,y)}</span>, <span class="math inline">f_{y}(y) =
        \int_{x \rightarrow \infty}^{}{F(x,y)}</span>.</p>
        <p>Složky <span class="math inline">X,Y</span> dvousložkového
        náhodného vektoru jsou navzájem nezávislé právě tehdy, jsou-li
        nezávislé náhodné veličiny <span class="math inline">X,Y</span>.
        Platí tedy, že <span class="math inline">F(x,y) =
        F_{x}(x)F_{y}(y)</span>. Z těchto údajů můžeme vytvořit
        korelační tabulku.</p>
        <p>Pro náhodný vektor je definována <strong>podmíněná
        pravděpodobnostní funkce</strong> <span
        class="math inline">f\left( x \middle| y \right) =
        \frac{f(x,y)}{f_{y}(y)}</span>.</p>
        <h2 id="charakteristiky-náhodného-vektoru">Charakteristiky
        náhodného vektoru</h2>
        <p>Smíšený obecný moment řádu <span
        class="math inline">k,n</span>: <span
        class="math inline">\mu_{kn}&#39; = E(X^{k}Y^{n})</span>.</p>
        <p>Smíšený centrální moment řádu <span
        class="math inline">k,n</span>: <span
        class="math inline">\mu_{kn} = E\left\lbrack (X - EX)^{k}(Y -
        EY)^{n} \right\rbrack</span></p>
        <p>Kovariance je nejjednodušším ukazatelem souvislosti dvou
        náhodných veličin <span class="math inline">Cov(X,Y) = \mu_{11}
        = E\left\lbrack (X - EX)(Y - EY) \right\rbrack</span>. Kladná
        hodnota kovariance znamená, že se zvětšením hodnoty <span
        class="math inline">X</span> se pravděpodobně zvýší i hodnota
        <span class="math inline">Y</span>, oproti tomu záporná hodnota
        kovariance znamená, že se zvětšením hodnoty <span
        class="math inline">X</span> se pravděpodobně sníží hodnota
        <span class="math inline">Y</span>. Často definujeme kovarianční
        matici <span class="math inline">\begin{bmatrix}
        DX &amp; Cov(X,Y) \\
        Cov(X,Y) &amp; DY
        \end{bmatrix}</span>.</p>
        <p>Jednoduchý korelační koeficient je mírou lineární závislosti
        dvou náhodných veličin definovaný jako <span
        class="math inline">\rho_{x,y} = \frac{Cov(X,Y)}{\sqrt{DX \cdot
        DY}}</span>. Mohou být nekorelované, pozitivně korelované a
        negativně korelované.</p>
        <h1 id="diskrétní-rozdělení-pravděpodobnosti">Diskrétní
        rozdělení pravděpodobnosti</h1>
        <p>Definujme <strong>Bernoulliho pokusy</strong> posloupnost
        nezávislých pokusů majících pouze 2 možné výsledky a
        pravděpodobnost výskytu události <span
        class="math inline">p</span> je konstantní v každém pokuse.</p>
        <p><strong>Poissonův proces</strong> popisuje výskyt náhodných
        událostí na nějakém pevném časovém intervalu – speciální případ
        bodového procesu. Každý proces musí dodržet následující
        předpoklady – rychlost výskytu událostí je konstantní v průběhu
        celého intervalu a jednotlivé události musí být nezávislé.</p>
        <h2 id="hypergeometrická-náhodná-veličina">Hypergeometrická
        náhodná veličina</h2>
        <p>Předpokládejme, že v souboru <span
        class="math inline">N</span> prvků <span
        class="math inline">M</span> prvků s danou vlastností a zbylých
        (<span class="math inline">N - M</span>) prvků tuto vlastnost
        nemá. Postupně vybereme ze souboru <span
        class="math inline">n</span> prvků, z nichž žádný nevracíme
        zpět. Definujme náhodnou veličinu <span
        class="math inline">X</span> jako počet se sledovanou vlastností
        ve výběru <span class="math inline">n</span> prvků, pak tato
        veličina má hypergeometrické rozdělení s parametry <span
        class="math inline">N,M,n</span>, což značíme <span
        class="math inline">X \rightarrow H(N;M;n)</span>.</p>
        <p><span class="math display">P(X = k) =
        \frac{\binom{M}{k}\binom{N - M}{n - k}}{\binom{N}{n}}</span></p>
        <p>Hypergeometrické rozdělení využijeme při statistické kontrole
        jakosti, když zkoumáme jakost malého počtu výrobků nebo když
        kontrola má ráz destrukční zkoušky.</p>
        <h2 id="binomická-náhodná-veličina">Binomická náhodná
        veličina</h2>
        <p>Binomická náhodná veličina <span class="math inline">X</span>
        je definována jako počet výskytu události v <span
        class="math inline">n</span> Bernoulliho pokusech. Pro rozložení
        veličiny <span class="math inline">X \rightarrow Bi(n,p)</span>
        musíme znát počet pokusů <span class="math inline">n</span> a
        pravděpodobnost výskytu události <span
        class="math inline">p</span>.</p>
        <p><span class="math display">P(X = k) = \binom{n}{k}p^{k}(1 -
        p)^{n - k}</span></p>
        <p>Je-li výběrový poměr <span
        class="math inline">\frac{n}{N}</span> v hypergeometrickém
        rozdělení menší než 0,05, lze hypergeometrické rozdělení
        nahradit binomickým <span class="math inline">H(N;M;n)
        \rightarrow Bi(n;\frac{M}{N})</span>.</p>
        <p>Variantou binomické veličiny pro <span class="math inline">n
        = 1</span> je <strong>alternativní náhodná veličina</strong>.
        Pokud <span class="math inline">X \rightarrow A(p)</span>, poté
        <span class="math inline">P(X = 1) = p</span>, <span
        class="math inline">P(X = 0) = 1 - p</span>.</p>
        <h2 id="geometrická-náhodná-veličina">Geometrická náhodná
        veličina</h2>
        <p>Geometrická náhodná veličina <span
        class="math inline">X</span> je definovaná jako počet
        Bernoulliho pokusů do prvního výskytu události, <strong>včetně
        něj</strong>. Značíme <span class="math inline">X \rightarrow
        G(p)</span>, kde <span class="math inline">p</span> je
        pravděpodobnost výskytu události.</p>
        <p><span class="math display">P(X = n) = p(1 - p)^{n -
        1}</span></p>
        <h2 id="negativně-binomická-náhodná-veličina">Negativně
        binomická náhodná veličina</h2>
        <p>Negativně binomická náhodná veličina <span
        class="math inline">X</span> je definována jako počet
        Bernoulliho pokus; do <span class="math inline">k</span>-tého
        výskytu události, včetně <span class="math inline">k</span>-tého
        výskytu. Geometrická náhodná veličina je speciálním případem
        negativně binomické náhodné veličiny pro <span
        class="math inline">k = 1</span>. Značíme <span
        class="math inline">X \rightarrow NB(k,p)</span>, kde <span
        class="math inline">k</span> je požadovaný počet výskytů
        událostí a <span class="math inline">p</span> je pravděpodobnost
        výskytu události.</p>
        <p><span class="math display">P(X = n) = \binom{n - 1}{k -
        1}p^{k}(1 - p)^{n - k}</span></p>
        <h2 id="poissonovo-rozdělení-pravděpodobnosti">Poissonovo
        rozdělení pravděpodobnosti</h2>
        <p>Definujme si náhodný pokus jako Poissonův proces probíhající
        v čase <span class="math inline">t</span> s rychlostí výskytu
        <span class="math inline">\lambda</span>. Pokud veličina <span
        class="math inline">X</span> značí počet výskytu události
        v časovém intervalu <span class="math inline">t</span> poté
        <span class="math inline">X \rightarrow Po(\lambda
        t)</span>.</p>
        <p><span class="math display">P(X = k) = \frac{(\lambda
        t)^{k}e^{- \lambda t}}{k!}</span></p>
        <p>Je-li počet pokusů <span class="math inline">n \rightarrow
        \infty</span> a pravděpodobnost výskytu události <span
        class="math inline">p \rightarrow 0</span>, poté můžeme
        binomické rozdělení aproximovat Poissonovým rozdělením <span
        class="math inline">Bi(n,p)\sim Po(\lambda),\lambda = np</span>.
        Dobrou aproximaci splňují podmínky <span class="math inline">n
        &gt; 30</span> a <span class="math inline">p &lt;
        0.3</span>.</p>
        <h1 id="spojitá-rozdělení-pravděpodobnosti">Spojitá rozdělení
        pravděpodobnosti</h1>
        <p>Pro nezápornou náhodnou veličinu <span
        class="math inline">X</span> se spojitým rozdělením definujeme
        pro <span class="math inline">F(t) \neq 1</span>
        <strong>intenzitu poruch</strong> <span
        class="math inline">\lambda(t) = \frac{f(t)}{1 - F(t)}</span>.
        Představuje-li náhodná veličina <span
        class="math inline">X</span> dobu do poruchy nějakého zařízení,
        pak intenzita poruch vyjadřuje, že pokud do času <span
        class="math inline">t</span> nedošlo k žádné poruše, tak
        pravděpodobnost, že k ní dojde v následujícím okamžiku malé
        délky <span class="math inline">dt</span>, je přibližně <span
        class="math inline">\lambda(t) \cdot dt</span>.</p>
        <p><img
        src="fakulta-elektrotechniky-a-informatiky-vsb-tu-ostrava-bakalarsky-am2401-statistika-i_media/media/image3.tmp"
        style="width:3.85in;height:2.025in" />Křivka na obrázku se
        nazývá <strong>vanová křivka</strong> a obvykle se dělí na tři
        úseky.</p>
        <ol type="1">
        <li><p>V prvním úseku křivka poruch klesá. Odpovídající časový
        interval se nazývá <strong>období časných poruch</strong>.
        Příčinou zvětšené intenzity poruch v tomto období jsou poruchy
        v důsledku výrobních vad, nesprávné montáže, chyb při návrhu
        nebo při výrobě.</p></li>
        <li><p>Ve druhém úseku dochází k běžnému využívání zaběhnutého
        výrobku, k poruchám dochází většinou z vnějších příčin,
        nedochází k opotřebení, které by změnilo funkční vlastnosti
        výrobku. Např. exponenciální rozdělení.</p></li>
        <li><p>Ve třetím úseku procesy stárnutí a opotřebení mění
        funkční vlastnosti výrobku, projevují se nastřádané otřesy,
        trhliny a intenzita poruch vzrůstá. Např. Erlangovo
        rozdělení.</p></li>
        </ol>
        <h2 id="rovnoměrné-rozložení">Rovnoměrné rozložení</h2>
        <p>Rozložení s hustotou pravděpodobností je konstantní na
        intervalu <span class="math inline">\left\langle a,b
        \right\rangle</span>. Náhodnou veličinu s tímto rozdělením
        značíme <span class="math inline">X \rightarrow
        R(a,b)</span></p>
        <p><span class="math display">f(x) = \left\{ \begin{array}{rlr}
        \frac{1}{b - a} &amp; &amp; x \in \left\langle a,b \right\rangle
        \\
        0 &amp; &amp; jinde
        \end{array} \right.\ </span></p>
        <h2 id="exponenciální-rozdělení">Exponenciální rozdělení</h2>
        <p>Mějme Poissonův proces, tj. v určitém časovém intervalu se
        s konstantní rychlostí výskytu <span
        class="math inline">\lambda</span> objevují události, které jsou
        na sobě nezávislé. Poté exponenciální rozdělení značí dobu do
        výskytu první události. Náhodnou veličinu <span
        class="math inline">X</span> s exponenciálním rozdělením značíme
        <span class="math inline">X \rightarrow E(\lambda)</span>, kde
        <span class="math inline">\lambda</span> je parametrem
        Poissonova procesu.</p>
        <p><span class="math display">f(t) = \lambda e^{- \lambda
        t}</span></p>
        <p>Exponenciální rozdělení bývá někdy nazýváno <strong>rozdělení
        bez paměti</strong> <span class="math inline">P\left( X &gt;
        \left( t_{1} + t_{2} \right) \middle| X &gt; t_{1} \right) = P(X
        &gt; t_{2})</span>. Toto rozdělení dobře popisuje dobu života
        zařízení, u kterých dochází k poruše ze zcela náhodných
        příčin.</p>
        <p>Exponenciální rozdělení je využito v teorii hromadné obsluhy
        nebo v teorii spolehlivosti.</p>
        <h2 id="erlangovo-rozdělení">Erlangovo rozdělení</h2>
        <p>Určitým zobecněním exponenciální náhodné veličiny je veličina
        s Erlangovým rozdělením, která popisuje dobu do výskytu <span
        class="math inline">k</span>-té události v Poissonově procesu.
        Erlangovo rozdělení je speciálním typem tzv. Gamma rozdělení pro
        <span class="math inline">k</span> z množiny celých čísel.
        Značíme <span class="math inline">X_{k} \rightarrow
        Erlang(k,\lambda)</span>, kde <span class="math inline">k</span>
        je počet událostí (parametr tvaru) a <span
        class="math inline">\lambda</span> je rychlost výskytu těchto
        událostí.</p>
        <p><span class="math display">f(t) = \lambda e^{- \lambda t}
        \cdot \frac{(\lambda t)^{k - 1}}{(k - 1)!}</span></p>
        <p>Intenzita poruch je v případě Erlangova rozdělení rostoucí
        funkce a proto je toto rozdělení vhodné pro modelování procesů
        stárnutí.</p>
        <h2 id="weibullovo-rozdělení">Weibullovo rozdělení</h2>
        <p><img
        src="fakulta-elektrotechniky-a-informatiky-vsb-tu-ostrava-bakalarsky-am2401-statistika-i_media/media/image4.tmp"
        style="width:4.02778in;height:1.80139in" />Weibullovo rozdělení
        je velmi flexibilní a proto se jím popisují veličiny jako doba
        do poruchy. Používá se při popisu komponent v období raných
        poruch nebo v období stárnutí. Weibullovo rozdělení má dva
        parametry <span class="math inline">\Theta</span> – parametr
        měřítka, scale, závisí na materiálu, namáhání a podmínkách
        užívání – a <span class="math inline">\beta</span> – parametr
        tvaru, shape, na jeho hodnotě závisí tvar intenzity poruch a tím
        i vhodnost použití pro určité období doby života. Veličinu
        značíme <span class="math inline">X \rightarrow
        W(\Theta,\beta)</span>.</p>
        <p><span class="math display">F(t) = 1 - e^{- \left(
        \frac{t}{\Theta} \right)^{\beta}}</span></p>
        <p>Pro intenzitu poruch platí <span
        class="math inline">\lambda(t) = konst. \cdot t^{\beta -
        1}</span>, tudíž tvar intenzity poruch závisí na volbě parametru
        <span class="math inline">\beta</span>.</p>
        <table>
        <colgroup>
        <col style="width: 13%" />
        <col style="width: 32%" />
        <col style="width: 53%" />
        </colgroup>
        <thead>
        <tr>
        <th><span class="math display">0 &lt; \beta &lt; 1</span></th>
        <th style="text-align: center;">období dětských nemocí</th>
        <th style="text-align: center;">klesající funkce</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td><span class="math display">\beta = 1</span></td>
        <td style="text-align: center;">období stabilního života</td>
        <td style="text-align: center;">exponenciální rozdělení</td>
        </tr>
        <tr>
        <td><span class="math display">1 &lt; \beta &lt; 2</span></td>
        <td style="text-align: center;">období stárnutí</td>
        <td style="text-align: center;">konvexní, rostoucí funkce</td>
        </tr>
        <tr>
        <td><span class="math display">\beta = 2</span></td>
        <td style="text-align: center;">období stárnutí</td>
        <td style="text-align: center;">lineárně rostoucí funkce</td>
        </tr>
        <tr>
        <td><span class="math display">\beta &gt; 2</span></td>
        <td style="text-align: center;">období stárnutí</td>
        <td style="text-align: center;">konkávní, rostoucí funkce</td>
        </tr>
        </tbody>
        </table>
        <h2 id="normální-rozdělení">Normální rozdělení</h2>
        <p>Lze říci, že normální rozdělení je vhodným pravděpodobnostním
        modelem tehdy, působí-li na kolísání náhodné veličiny velký
        počet nepatrných a vzájemně nezávislých vlivů. Za určitých
        podmínek lze pomocí něj aproximovat řadu jiných spojitých i
        nespojitých rozdělení. Normální rozdělení má dva parametry:
        <span class="math inline">\mu</span> – střední hodnotu
        charakterizující polohu a <span
        class="math inline">\sigma^{2}</span> – rozptyl. Náhodnou
        veličinu s normálním rozdělením značíme <span
        class="math inline">X \rightarrow N\left( \mu;\sigma^{2}
        \right)</span>.</p>
        <p><span class="math display">f(x) =
        \frac{1}{\sigma\sqrt{2\pi}}e^{{- \left( \frac{x -
        \mu}{\sqrt{2}\sigma} \right)}^{2}}</span></p>
        <h3 id="normované-normální-rozdělení">Normované normální
        rozdělení</h3>
        <p>Normální rozdělení se středním hodnotou rovnou nule a
        jednotkovým rozptylem. To, že má náhodná veličina <span
        class="math inline">Z \rightarrow N(0,1)</span>.</p>
        <p><span class="math display">\varphi(x) = \frac{1}{\sqrt{2\pi}}
        \cdot e^{- \frac{x^{2}}{2}}</span></p>
        <p>Nechť <span class="math inline">X \rightarrow N\left(
        \mu,\sigma^{2} \right)</span>, poté definujme <span
        class="math inline">Z = \frac{X - \mu}{\sigma}</span> se
        stejným, ale normovaným rozdělením. Mezi distribuční funkci
        normální a normované normální náhodné veličiny plat vztah <span
        class="math inline">F(x) = \Phi\left( \frac{x - \mu}{\sigma}
        \right)</span>.</p>
        <p>Pravidlo <span class="math inline">6\sigma</span> je jedním
        ze základních principů, na nichž stojí kontrola kvality a
        jakosti. Máme-li data pocházející z normálního rozdělení o
        parametrech <span class="math inline">\mu,\sigma^{2}</span>, pak
        téměř všechna (99,8 %) leží v intervalu <span
        class="math inline">\mu \pm 3\sigma</span>.</p>
        <h2 id="mathbfchimathbf2-rozdělení"><span
        class="math inline">\mathbf{\chi}^{\mathbf{2}}</span>
        rozdělení</h2>
        <p>Nechť <span class="math inline">Z_{1},\ldots,Z_{n}</span>
        jsou nezávislé náhodné veličiny, <span class="math inline">Z_{i}
        \rightarrow N(0,1)</span>. Poté náhodná veličina <span
        class="math inline">\chi_{n}^{2} = \sum_{}^{}Z_{i}^{2}
        \rightarrow \chi^{2}(n)</span> má chí-kvadrát rozdělení o <span
        class="math inline">n</span> stupních volnosti. <span
        class="math inline">E\left( \chi_{n}^{2} \right) = n</span>,
        <span class="math inline">D\left( \chi_{n}^{2} \right) =
        2n</span>.</p>
        <h2 id="studentovo-rozdělení">Studentovo rozdělení</h2>
        <p>Náhodná veličina <span class="math inline">t_{n} =
        \frac{Z}{\sqrt{\frac{\chi_{n}^{2}}{n}}}</span> má Studentovo
        rozdělení o <span class="math inline">n</span> stupních
        volnosti. <span class="math inline">E\left( \chi_{n}^{2} \right)
        = 0</span>, <span class="math inline">D\left( \chi_{n}^{2}
        \right) = \frac{n}{n - 2}</span>. Tvarem Studentova rozdělení je
        také symetrická zvonovitá křivka, stejně jako o normálního
        rozdělení. Pro velká <span class="math inline">n</span> je
        rozdělení blízké k <span class="math inline">N(0,1)</span>.</p>
        <h2 id="fisherovo-snedecorovo-rozdělení">Fisherovo-Snedecorovo
        rozdělení</h2>
        <p>Náhodná veličina <span class="math inline">F_{n,m} =
        \frac{\frac{\chi_{m}^{2}}{n}}{\frac{\chi_{m}^{2}}{m}}</span> má
        Fisherovo-Snedecorovo rozdělení o <span
        class="math inline">m</span> a <span
        class="math inline">n</span> stupních volnosti. <span
        class="math inline">E\left( F_{m,n} \right) = \frac{m}{m -
        2}</span>. Pro velká <span class="math inline">m</span> se
        střední hodnota blíží k <span class="math inline">1</span>.</p>
        <h1 id="limitní-věty">Limitní věty</h1>
        <p>Definujme <strong>konvergenci podle pravděpodobnosti ke
        konstantě</strong>: je dána posloupnost náhodných veličin <span
        class="math inline">\left\{ X_{n} \right\} =
        (X_{1},\ldots,X_{n})</span> a reálné číslo <span
        class="math inline">a</span>, poté pokud pro <span
        class="math inline">\varepsilon &gt; 0</span> platí <span
        class="math inline">\lim_{n \rightarrow \infty}{P\left( \left|
        X_{n} - a \right| &lt; \varepsilon \right)} = 1</span>, pak
        říkáme posloupnost <span class="math inline">\{ X_{n}\}</span>
        konverguje k <span class="math inline">a</span> podle
        pravděpodobnosti. Značíme <span
        class="math inline">X_{n}\overset{p}{\rightarrow}\mu</span>.</p>
        <p>Definujme <strong>konvergenci v distribuci</strong>: je dána
        posloupnost náhodných veličin <span class="math inline">\left\{
        X_{n} \right\}</span> a náhodná veličina <span
        class="math inline">X</span> s distribuční funkcí <span
        class="math inline">F(x)</span>. Jestliže <span
        class="math inline">\lim_{n \rightarrow \infty}{F_{n}(x)} =
        F(x)</span>, pak říkáme, že posloupnost náhodných veličin <span
        class="math inline">\left\{ X_{n} \right\}</span> konverguje k
        náhodné veličině <span class="math inline">X</span> v distribuci
        a <span class="math inline">F(x)</span> nazýváme
        <strong>asymptotickou distribuční funkcí</strong>. Poté můžeme
        náhodnou veličinu <span class="math inline">X_{n}</span>
        aproximovat asymptotickou distribučních funkcí.</p>
        <p>Je-li <span class="math inline">X</span> libovolná náhodná
        veličina se střední hodnotou <span class="math inline">EX</span>
        a konečným rozptylem <span class="math inline">DX =
        \sigma^{2}</span>, pak <strong>Čebyševova</strong>
        <strong>nerovnost</strong> odhaduje pravděpodobnost odchylky
        náhodné veličiny <span class="math inline">X</span> od její
        střední hodnoty.</p>
        <p><span class="math display">\forall\epsilon &gt; 0:P\left( |X
        - EX| \geq \varepsilon \right) \leq
        \frac{DX}{\varepsilon^{2}}</span></p>
        <p>Čebyševova nerovnost pro případ, kdy chceme odhadnout
        pravděpodobnost, že náhodná veličina <span
        class="math inline">X</span> je od své střední hodnoty vzdálená
        o více než <span class="math inline">k</span>-násobek směrodatná
        odchylky <span class="math inline">\sigma</span></p>
        <p><span class="math display">\forall\sigma,k &gt; 0:P\left( |X
        - EX| \geq k\sigma \right) \leq \frac{1}{k^{2}}</span></p>
        <p><strong>Zákon velkých čísel</strong> označuje tvrzení o
        konvergenci průměru v posloupnosti náhodných veličin: <span
        class="math inline">X_{1},\ldots,X_{n}</span> jsou nezávislé
        náhodné veličiny, jejichž střední hodnoty jsou rovny <span
        class="math inline">\mu</span>. Jestliže  <span
        class="math inline">\overline{X_{n}}</span> definujeme jako
        <span class="math inline">\overline{X_{n}} = \frac{1}{n}\sum_{j
        = 1}^{n}X_{j}</span>, pak posloupnost <span
        class="math inline">\left(
        \overline{X_{n}}\overset{p}{\rightarrow}\mu \right)</span>.
        Posloupnost nemusí mít stejné rozdělení, a zároveň nemáme žádné
        požadavky na jejich rozptyl.</p>
        <p>Důsledkem zákona velkých čísel je <strong>Bernoulliho
        věta</strong>, která tvrdí, že relativní četnost sledovaného
        jevu stochasticky konverguje (konverguje podle pravděpodobnosti)
        k jeho pravděpodobnosti. Nechť <span
        class="math inline">X_{1},X_{2},\ldots</span> jsou nezávislé
        náhodné veličiny s alternativním rozdělením s parametrem <span
        class="math inline">p</span>, jestliže <span
        class="math inline">\overline{X_{n}}</span> definujeme jako
        <span class="math inline">\overline{X_{n}} = \frac{1}{n}\sum
        X_{j}</span>, pak <span
        class="math inline">(\overline{X_{n}}\overset{p}{\rightarrow}p)</span>.</p>
        <h2 id="centrální-limitní-věta">Centrální limitní věta</h2>
        <p>O náhodných veličinách, jež konvergují v distribuci
        k normálnímu rozdělení, říkáme, že mají <strong>asymptoticky
        normální rozdělení</strong>.</p>
        <p><strong>Lindenberg-Lévy</strong> – jestliže <span
        class="math inline">X_{1},\ldots,X_{n}</span> jsou nezávislé
        náhodné veličiny se stejnými středními hodnotami <span
        class="math inline">\mu</span> a se stejnými rozptyly <span
        class="math inline">\sigma^{2}</span>, pak platí</p>
        <p><span class="math display">Y_{n} = \frac{\sum_{}^{}{X_{i} -
        n\mu}}{\sigma\sqrt{n}} \Rightarrow \lim_{n \rightarrow
        \infty}{P(Y_{n} &lt; u)} = \Phi(u)</span></p>
        <p>Čili <span class="math inline">Y_{n}</span> má asymptoticky
        normální rozdělení <span class="math inline">N(0,1)</span>.
        Proto platí, že</p>
        <ol type="1">
        <li><p><span class="math inline">X = \sum_{}^{}X_{i} \Rightarrow
        EX = n\mu,DX = n\sigma^{2}</span>,<br />
        rozdělení náhodné veličiny <span class="math inline">X</span>
        lze aproximovat rozdělením <span class="math inline">N\left(
        n\mu;n\sigma^{2} \right)</span></p></li>
        <li><p><span class="math inline">\overline{X} =
        \frac{\sum_{}^{}X_{i}}{n} = \frac{X}{n} \Rightarrow
        E\overline{X} = \mu,D\overline{X} = \frac{\sigma^{2}}{n}\
        </span><br />
        rozdělení náhodné veličiny <span
        class="math inline">\overline{X}</span> lze aproximovat
        rozdělením <span class="math inline">N\left(
        \mu,\frac{\sigma^{2}}{n} \right)</span></p></li>
        </ol>
        <p><strong>Moivre-Laplace</strong> – nechť <span
        class="math inline">X \rightarrow Bi(n;p),EX = np;DX = np(1 -
        p)</span>, potom pro velká <span class="math inline">n</span>
        platí, že:</p>
        <p><span class="math display">U = \frac{X - np}{\sqrt{np(1 -
        p)}} \rightarrow N(0,1)</span></p>
        <p>Aproximace binomického rozdělení normálním se zlepšuje
        s rostoucím rozptylem. Poměrně dobré výsledky dává tato
        aproximace v případě, že <span class="math inline">np(1 - p)
        &gt; 9</span> nebo <span class="math inline">\min\left\{ np;n(1
        - p) \right\} &gt; 5</span>.</p>
        <p><strong>Aproximace rozdělení výběrové relativní četnosti
        normálním rozdělením</strong> – máme-li <span
        class="math inline">n</span> Bernoulliho pokusů, při kterých
        nastane <span class="math inline">k</span> výskytů nějaké
        události, můžeme určit výběrovou relativní četnost <span
        class="math inline">p = \frac{k}{n} =
        \frac{\sum_{}^{}X_{i}}{n}</span>, kde <span
        class="math inline">X_{i} \rightarrow A(\pi)</span>. Na základě
        Lindenberg-Lévy můžeme tento součet aproximovat normálním
        rozdělením <span class="math inline">\ \sum_{}^{}X_{i} = N\left(
        n\pi,n\pi(1 - \pi) \right)</span>, jejich průměr <span
        class="math inline">p \rightarrow N\left( \pi,\frac{\pi(1 -
        \pi)}{\pi} \right)</span> a <span class="math inline">\frac{p -
        \pi}{\sqrt{\frac{\pi(1 - \pi)}{\pi}}} \rightarrow N(0,1)</span>.
        Pro přesnější výpočty se provádí <strong>oprava na
        spojitost</strong>.</p>
        <p><span class="math display">P\left( k_{1} &lt; \sum_{}^{}X_{i}
        &lt; k_{2} \right) = F\left( k_{2} \right) - F\left( k_{1}
        \right) \approx \Phi\left( \frac{k_{2} + 0.5 - np}{\sqrt{np(1 -
        p)}} \right) - \Phi\left( \frac{k_{1} - 0.5 - np}{\sqrt{np(1 -
        p)}} \right)</span></p>
        <p><strong>Aproximace Poissonova rozdělení normálním
        rozdělením</strong> – pokud interval <span
        class="math inline">(0,t)</span> je dostatečně velký, lze
        Poissonovo rozdělení aproximovat <span class="math inline">X
        \rightarrow Po(\lambda t) \rightarrow N(\lambda t,\lambda
        t)</span> pro dostatečně velké <span
        class="math inline">t</span>. Dále lze průměrný počet výskytů
        událostí za časovou jednotku aproximovat normálním rozdělením
        <span class="math inline">Y = \frac{X}{t} \rightarrow N\left(
        \lambda,\frac{\lambda}{t} \right)</span>.</p>
        <p><span class="math display">P\left( k_{1} &lt; X &lt; k_{2}
        \right) = F\left( k_{2} \right) - F\left( k_{1} \right) \approx
        \Phi\left( \frac{k_{2} + 0.5 - \lambda t}{\sqrt{\lambda t}}
        \right) - \Phi\left( \frac{k_{1} - 0.5 - \lambda
        t}{\sqrt{\lambda t}} \right)</span></p>
        <h1 id="náhodné-výběry-a-jejich-zpracování">Náhodné výběry a
        jejich zpracování</h1>
        <p><strong>Náhodný výběr</strong> je speciální náhodný vektor,
        jehož složky jsou nezávislé náhodné veličiny se stejným
        rozdělením pravděpodobnosti. Opakujeme-li <span
        class="math inline">n</span>-krát nezávisle pokus, jehož
        výsledkem je náhodná veličina <span class="math inline">X</span>
        s distribuční funkcí <span class="math inline">F(x)</span>,
        sledujeme náhodný výběr <span
        class="math inline">\overset{\underline{}}{X} = \left(
        X_{1},\ldots,X_{n} \right),X_{i}\sim F(x)</span> z rozdělení
        <span class="math inline">F(x)</span>, kde <span
        class="math inline">n</span> značí rozsah výběru. Obvykle
        rozdělujeme náhodné výběry na <strong>malé</strong> pro <span
        class="math inline">n \leq 30</span> a <strong>velké</strong>
        pro <span class="math inline">n &gt; 30</span>. Náhodný výběr má
        simultánní distribuční funkci <span class="math inline">F\left(
        \overset{\underline{}}{x} \right) = \prod_{}^{}{F\left( x_{i}
        \right)}</span> a simultánní hustotu pravděpodobností <span
        class="math inline">f\left( \overset{\underline{}}{x} \right) =
        \prod_{}^{}{f\left( x_{i} \right)}</span>.</p>
        <ol type="1">
        <li><p><span class="math inline">T_{1}\left(
        \overset{\underline{}}{X} \right) = \overline{X_{n}} =
        \frac{\sum_{i}^{}X_{i}}{n}</span>, <span
        class="math inline">E\overline{X_{n}} = EX_{i}</span><br />
        výběrový průměr pro odhad střední hodnoty</p></li>
        <li><p><span class="math inline">T_{2}\left(
        \overset{\underline{}}{X} \right) = \frac{1}{n -
        1}\sum_{i}^{}\left( X_{i} - \overline{X_{n}} \right)^{2}</span>,
        <span class="math inline">E\left( T_{2}\left(
        \overset{\underline{}}{X} \right) \right) = DX_{i}</span><br />
        výběrový rozptyl, <span class="math inline">T_{3}\left(
        \overset{\underline{}}{X} \right) = \sqrt{T_{2}\left(
        \overset{\underline{}}{X} \right)} = S</span> výběrová
        směrodatná odchylka</p></li>
        </ol>
        <blockquote>
        <p>Předpokládejme, že <span
        class="math inline">\overset{\underline{}}{X} = \left(
        X_{1},\ldots,X_{n} \right),X_{i} \rightarrow N\left(
        \mu,\sigma^{2} \right)</span>. Definujme výběrová rozdělení</p>
        </blockquote>
        <ol type="1">
        <li><p><span class="math inline">\overline{X_{n}} \rightarrow
        N\left( \mu,\frac{\sigma^{2}}{n} \right)</span></p></li>
        <li><p><span class="math inline">Z_{n} = \frac{\overline{X_{n}}
        - \mu}{\sigma}\sqrt{n} \rightarrow N(0,1)</span></p></li>
        <li><p><span class="math inline">\frac{S_{n}^{2}}{\sigma^{2}}(n
        - 1) \rightarrow \chi^{2}(n - 1)</span><br />
        <em>jeden stupeň volnosti ztrácíme na náhradu</em> <span
        class="math inline">\mu</span> <em>za</em> <span
        class="math inline">\overline{X_{n}}</span></p></li>
        <li><p><span class="math inline">\frac{\left( \overline{X_{n}} -
        \mu \right)}{S}\sqrt{n} \rightarrow t_{n - 1}</span></p></li>
        </ol>
        <p>Předpokládejme navíc, že <span
        class="math inline">\overset{\underline{}}{Y} = \left(
        Y_{1},\ldots,Y_{m} \right),Y_{i} \rightarrow N\left(
        \mu&#39;,{\sigma&#39;}^{2} \right)</span>.</p>
        <ol start="5" type="1">
        <li><p><span class="math inline">\frac{\overline{X} -
        \overline{Y} - \left( \mu - \mu&#39;
        \right)}{\sqrt{\frac{\sigma^{2}}{n} +
        \frac{\sigma^{&#39;2}}{m}}} \rightarrow N(0,1)</span></p></li>
        <li><p><span
        class="math inline">\frac{\frac{\frac{S_{x}^{2}}{\sigma^{2}}(n -
        1)}{n - 1}}{\frac{\frac{S_{y}^{2}}{\sigma^{&#39;2}}(m - 1)}{m -
        1}} =
        \frac{\frac{S_{x}^{2}}{\sigma^{2}}}{\frac{S_{y}^{2}}{\sigma^{&#39;2}}}
        \rightarrow F_{n - 1,m - 1}</span></p></li>
        </ol>
        <p>Předpokládejme navíc, že <span
        class="math inline">\sigma_{x}^{2} = \sigma_{y}^{2}</span>.</p>
        <ol start="7" type="1">
        <li><p><span class="math inline">\frac{\overline{X} -
        \overline{Y} - \left( \mu - \mu&#39; \right)}{\sqrt{S_{x}^{2}(n
        - 1) + S_{y}^{2}(m - 1)}} \cdot \sqrt{\frac{nm}{n + m}} \cdot
        \sqrt{n + m - 2} \rightarrow t_{n + m - 2}</span></p></li>
        </ol>
        <h2 id="teorie-odhadu">Teorie odhadu</h2>
        <p>Nechť máme náhodný výběr <span
        class="math inline">\overset{\underline{}}{X} = \left(
        X_{1},\ldots,X_{n} \right)\sim F(x,\Theta)</span>. Cílem naší
        teorie odhadu je pro známé pravděpodobnostní rozdělení <span
        class="math inline">F</span> najít parametr <span
        class="math inline">\Theta \in \Omega</span>, kde <span
        class="math inline">\Omega</span> značí parametrický prostor
        pomocí výběrové charakteristiky <strong>odhadu</strong> <span
        class="math inline">\widehat{\Theta} = T\left(
        \overset{\underline{}}{X} \right)</span> pro nalezení
        <strong>bodového odhadu</strong> <span
        class="math inline">t(\overset{\underline{}}{x})</span>. Aby
        odhad byl přesný, požadujeme splnění tří vlastností odhadu –
        nestrannost, konzistence a efektivita.</p>
        <p><strong>Nestrannost odhadu</strong> – požadujeme, aby <span
        class="math inline">\forall\Theta \in \Omega:E\widehat{\Theta} =
        \Theta</span>. Často požadujeme, aby byl odhad alespoň
        <strong>asymptoticky nestranný</strong> <span
        class="math inline">\forall\Theta \in \Omega:{\lim_{n
        \rightarrow \infty}{E\widehat{\Theta}}}_{n} = \Theta</span>.</p>
        <ul>
        <li><p>Výběrový průměr <span
        class="math inline">\widehat{\Theta} = \overline{X}</span> je
        nestranným odhadem střední hodnoty.</p></li>
        </ul>
        <p><strong>Konzistence odhadu</strong> – požadujeme, aby byl
        nestranný nebo asymptoticky nestranný a zároveň <span
        class="math inline">\lim_{n \rightarrow
        \infty}{D{\widehat{\Theta}}_{n}} = 0</span>.</p>
        <ul>
        <li><p>Výběrový průměr <span
        class="math inline">\widehat{\Theta} = \overline{X}</span> je
        konzistentním odhadem střední hodnoty, neboť <span
        class="math inline">D\widehat{\Theta} =
        \frac{\sigma^{2}}{n}\overset{\rightarrow}{n \rightarrow
        \infty}0</span>.</p></li>
        </ul>
        <p><strong>Efektivnost odhadu</strong> – odhad je efektivní,
        značíme <span class="math inline">{\widehat{\Theta}}_{0}</span>,
        právě tehdy když je nestranný a zároveň <span
        class="math inline">\forall{\widehat{\Theta}}_{1},E{\widehat{\Theta}}_{1}
        = \Theta:D{\widehat{\Theta}}_{0} \leq
        D{\widehat{\Theta}}_{1}</span>.</p>
        <h3 id="intervalový-odhad">Intervalový odhad</h3>
        <p>Často hledáme <strong>intervalový odhad</strong> – hledáme
        funkce <span
        class="math inline">T_{D}(\overset{\underline{}}{X})</span> a
        <span
        class="math inline">T_{H}(\overset{\underline{}}{X})</span> tak,
        aby <span class="math inline">P\left( T_{D} \leq \Theta \leq
        T_{H} \right) = 1 - \alpha</span>, kde <span
        class="math inline">\alpha</span> je nejčastěji <span
        class="math inline">0.01</span>. Těmto mezím říkáme
        <strong>interval spolehlivosti pro</strong> <span
        class="math inline">\mathbf{\Theta}</span> se spolehlivostí
        <span class="math inline">1 - \alpha</span>. Konkrétní
        reprezentaci <span class="math inline">t_{D}\left(
        \overset{\underline{}}{X} \right)</span> a <span
        class="math inline">t_{H}(\overset{\underline{}}{X})</span>
        nazýváme <strong>intervalový odhad pro</strong> <span
        class="math inline">\mathbf{\Theta}</span> se spolehlivostí
        <span class="math inline">1 - \alpha</span>.</p>
        <p>Rozdělme <span class="math inline">\alpha = \alpha_{1} +
        \alpha_{2};\alpha_{1},\alpha_{2} \geq 0</span> tak, aby <span
        class="math inline">P\left( \Theta \leq T_{H}\left(
        \overset{\underline{}}{X} \right) \right) = 1 -
        \alpha_{2}</span> a <span class="math inline">P\left( \Theta
        &lt; T_{D}\left( \overset{\underline{}}{X} \right) \right) =
        \alpha_{1}</span>. Nejčastěji volíme <span
        class="math inline">\alpha_{1} = \alpha_{2} =
        \frac{\alpha}{2}</span> nebo <span
        class="math inline">\alpha_{1} = \alpha,\alpha_{2} = 0</span>
        pro jednostranný interval spolehlivosti.</p>
        <ol type="1">
        <li><p>Zvolme vhodnou <span class="math inline">T\left(
        \overset{\underline{}}{X} \right)</span>, ze které jsme schopni
        odvodit <span class="math inline">T_{D}</span> a <span
        class="math inline">T_{H}</span>.</p></li>
        <li><p>Algebraickou metodou najděme <span
        class="math inline">T_{D}</span> a <span
        class="math inline">T_{H}</span>.</p></li>
        </ol>
        <h2 id="testování-hypotéz">Testování hypotéz</h2>
        <p>Testování hypotéz je pojat jako rozhodovací proces, v němž
        proti sobě stojí dvě tvrzení. <strong>Nulová hypotéza</strong>
        <span class="math inline">H_{0}</span> představuje rovnovážný
        stav, bývá vyjádřena rovností. Jde o tvrzení o populaci, které
        je bráno jako předpoklad při testování. Oproti ní stavíme tzv.
        <strong>alternativní hypotézu</strong> <span
        class="math inline">H_{A}</span>. Ta představuje porušení
        rovnovážného stavu a zapisujeme je nerovností nebo nerovnicí.
        Alternativní hypotézu volíme v souladu s daty.</p>
        <p><strong>Čistý test významnosti</strong> zodpovídá otázku, zda
        získaný náhodný výběr <span
        class="math inline">\overset{\underline{}}{X}</span> je či není
        extrémní s ohledem na testovanou hypotézu (zda zjištěné údaje
        podporují nulovou hypotézu).</p>
        <ol type="1">
        <li><p>Formulace nulové hypotézy <span
        class="math inline">H_{0}</span> a alternativní hypotézy <span
        class="math inline">H_{A}</span>.</p></li>
        <li><p>Volba testové statistiky <span
        class="math inline">T(\overset{\underline{}}{X})</span> – funkce
        výběru, která vyjadřuje sílu platnosti nulové hypotézy ve
        srovnání s hypotézou alternativní. Je třeba znát nulové
        rozdělení <span class="math inline">F_{0}(x) = P\left( T\left(
        \overset{\underline{}}{X} \right) &lt; x \middle| H_{0}
        \right)</span>.</p></li>
        <li><p>Výpočet pozorované hodnoty testové statistky <span
        class="math inline">x_{OBS}</span>.</p>
        <ol type="a">
        <li><p>Je-li <span class="math inline">H_{A}</span> ve tvaru
        „<span class="math inline">&lt;</span>“: <span
        class="math inline">p_{value} = F_{0}\left( x_{OBS}
        \right)</span>.</p></li>
        <li><p>Je-li <span class="math inline">H_{A}</span> ve tvaru
        „<span class="math inline">&gt;</span>“: <span
        class="math inline">p_{value} = 1 - F_{0}\left( x_{OBS}
        \right)</span>.</p></li>
        <li><p>Je-li <span class="math inline">H_{A}</span> ve tvaru
        „<span class="math inline">\neq</span>“ a nulové rozdělení je
        symetrické: <span class="math inline">p_{value} = 2\min\left\{
        F_{0}\left( x_{OBS} \right);1 - F_{0}\left( x_{OBS} \right)
        \right\}</span>.</p></li>
        </ol></li>
        <li><p><span class="math inline">p_{value}</span> určuje
        minimální hladinu významnosti, na níž bychom při daném výběrovém
        souboru mohli nulovou hypotézu zamítnout. Čím menší je <span
        class="math inline">p_{value}</span>, tím silnější je výpověď
        náhodného výběru proti nulové hypotéze. Nejběžněji:</p>
        <ol type="a">
        <li><p>Je-li <span class="math inline">p_{value} &lt; 0.01 =
        \alpha</span>: zamítáme <span
        class="math inline">H_{0}</span>.</p></li>
        <li><p>Je-li <span class="math inline">0.01 &lt; p_{value} &lt;
        0.05</span>: nedokážeme rozhodnout.</p></li>
        <li><p>Je-li <span class="math inline">p_{value} &gt;
        0.05</span>: nezamítáme <span
        class="math inline">H_{0}</span>.</p></li>
        </ol></li>
        </ol>
        <p>Jelikož při rozhodování o nulové hypotéze vycházíme
        z výběrového souboru, který nemusí dostatečně přesně odpovídat
        vlastnostem základního souboru, můžeme se při rozhodování
        dopustit chyby.</p>
        <table>
        <colgroup>
        <col style="width: 24%" />
        <col style="width: 11%" />
        <col style="width: 31%" />
        <col style="width: 31%" />
        </colgroup>
        <thead>
        <tr>
        <th style="text-align: center;"></th>
        <th colspan="3" style="text-align: center;">VÝSLEDEK TESTU</th>
        </tr>
        </thead>
        <tbody>
        <tr>
        <td rowspan="3" style="text-align: center;">SKUTEČNOST</td>
        <td style="text-align: center;"></td>
        <td style="text-align: center;">Nezamítáme <span
        class="math inline">H_{0}</span></td>
        <td style="text-align: center;">Zamítáme <span
        class="math inline">H_{0}</span></td>
        </tr>
        <tr>
        <td style="text-align: center;">Platí <span
        class="math inline">H_{0}</span></td>
        <td style="text-align: center;">OK, pravděpodobnost <span
        class="math inline">1 - \alpha</span> zvaná
        <em>spolehlivost</em></td>
        <td style="text-align: center;"><strong>Chyba 1. druhu</strong>,
        pravděpodobnost <span class="math inline">\alpha</span> zvaná
        <em>hladina významnosti</em></td>
        </tr>
        <tr>
        <td style="text-align: center;">Platí <span
        class="math inline">H_{A}</span></td>
        <td style="text-align: center;"><strong>Chyba 2. druhu</strong>,
        pravděpodobnost <span class="math inline">\beta</span></td>
        <td style="text-align: center;">OK, pravděpodobnost <span
        class="math inline">\gamma ≔ 1 - \beta</span> zvaná <em>síla
        testu</em></td>
        </tr>
        </tbody>
        </table>
        <p><img
        src="fakulta-elektrotechniky-a-informatiky-vsb-tu-ostrava-bakalarsky-am2401-statistika-i_media/media/image5.tmp"
        style="width:1.95833in;height:1.25in" />Pravděpodobnost chyby 2.
        druhu závisí na přesné hodnotě alternativní hypotézy. Dokážeme
        určit <span class="math inline">\beta</span> pro případ, že
        alternativní hypotéza je přesně specifikována.
        <strong>Operativní charakteristika</strong> je závislost
        pravděpodobnosti chyby 2. druhu na přesné specifikaci
        alternativní hypotézy.</p>
        <p>Při testování více než dvou hypotéz nelze použít testování
        „po dvojicích“, neboť <span class="math inline">P\left(
        \min{p_{1},\ldots,p_{k}} &lt; p \right) \approx np \sim
        1</span>.</p>
        <h2 id="anova-analýza-rozptylu">ANOVA Analýza rozptylu</h2>
        <p>Předpokládejme <span class="math inline">k</span> datových
        tříd z normálního rozdělení a mající stejný rozptyl –
        homeskedaticitu, každá z nich <span
        class="math inline">n_{i}</span> hodnot (<span
        class="math inline">N = \sum_{i}^{}n_{i}</span>). Testujeme
        hypotézu <span class="math inline">H_{0}:\mu_{1} = \ldots =
        \mu_{k}</span> proti alternativně <span
        class="math inline">H_{A}:\neg H_{0}</span>. Hledáme takovou
        testovou statistiku <span class="math inline">F</span>, která
        nejen umožní implementaci <span
        class="math inline">H_{0}</span>, ale je i citlivá na platnost
        <span class="math inline">H_{0}</span>.</p>
        <p>Sestavme <strong>totální variabilitu</strong> <span
        class="math inline">SS_{T} = \sum_{i = 1}^{k}{\sum_{j =
        1}^{n_{i}}\left( X_{ij} - \overline{X} \right)^{2}}</span>, kde
        <span class="math inline">\overline{X}</span> je výběrový průměr
        ze všech pozorovaných hodnot. Rozdělme <span
        class="math inline">SS_{T} = SS_{w} + SS_{B} = \sum_{i =
        1}^{k}{\sum_{j = 1}^{n_{i}}\left( X_{ij} - \overline{X_{i}}
        \right)^{2}} + \sum_{i = 1}^{k}{n_{i}\left( \overline{X_{i}} -
        \overline{X} \right)^{2}}</span>, kde <span
        class="math inline">SS_{W}</span> je vnitřní variabilita a <span
        class="math inline">SS_{B}</span> je mezitřídní variabilita.
        Zaveďme <strong>vnitřní výběrový rozptyl</strong> jako <span
        class="math inline">S_{W}^{2} = \frac{SS_{W}}{N - k}</span>,
        <strong>mezitřídní výběrový rozptyl</strong> <span
        class="math inline">S_{B}^{2} = \frac{SS_{B}}{k - 1}</span> a
        <strong>F-poměr</strong> jako <span class="math inline">F =
        \frac{S_{B}^{2}}{S_{W}^{2}} \rightarrow F_{k - 1,N -
        k}</span>.</p>
        <p><strong>Post Hoc</strong> je proces, který provádíme
        v případě, že zamítneme <span class="math inline">H_{0}</span>.
        Cílem je vytvořit takové rozdělení datových tříd, v rámci
        kterých platí <span class="math inline">H_{0}</span>. Můžeme
        využít statistiku <span class="math inline">LSD_{i,j} =
        \frac{\overline{X_{i}} - \overline{X_{j}} - \left( \mu_{i} -
        \mu_{j} \right)}{\sqrt{\frac{\sigma^{2}}{n_{i}} +
        \frac{\sigma^{2}}{n_{j}}}} \cdot
        \frac{1}{\sqrt{\frac{\frac{S_{W}^{2}}{\sigma^{2}}(N - k)}{N -
        k}}} = \frac{\overline{X_{i}} - \overline{X_{j}}}{S_{W} \cdot
        \sqrt{\frac{1}{n_{i}} + \frac{1}{n_{j}}}}</span> pro
        porovnání.</p>
        <p>V případě, že nejsou splněny požadavky ANOVA analýzy, můžeme
        využít <strong>Kruskal-Wallisův test</strong>, kde rozhodujeme o
        <span class="math inline">H_{0}:x_{{0.5}_{1}} = \ldots =
        x_{{0.5}_{k}}</span>.</p>
        <h1 id="regresní-analýza">Regresní analýza</h1>
        <p><strong>Regrese</strong> značí systematické změny jedněch
        veličin při změnách jiných veličin a popis těchto změn
        matematickými funkcemi. Snažíme se tedy napozorované hodnoty
        vyrovnat vhodnou matematickou funkcí.</p>
        <p><strong>Vysvětlovaná (závisle) proměnná</strong> – proměnná
        v regresním modelu, jejíž chování se snažíme vysvětlit, popsat
        matematickou křivkou. Jedná se o proměnnou na levé straně
        regresní funkce a většinou ji označujeme symbolem <span
        class="math inline">A</span>. <strong>Vysvětlující (nezávisle)
        proměnné</strong> – proměnné v regresním modelu, jejichž chování
        vysvětluje chování závisle proměnné <span
        class="math inline">Y</span>. Jedná se o proměnné na pravé
        straně regresní funkce a většinou je označujeme symboly <span
        class="math inline">X,Z,\ldots</span>.</p>
        <h2 id="obecný-lineární-model">Obecný lineární model</h2>
        <p><span class="math display">\overset{\underline{}}{Y} =
        \mathbf{X}\overset{\underline{}}{\beta} +
        \overset{\underline{}}{e}</span></p>
        <ul>
        <li><p><span
        class="math inline">\overset{\underline{}}{Y}</span> je náhodný
        vektor <span class="math inline">n</span> hodnot vysvětlované
        proměnné</p></li>
        <li><p><span class="math inline">\mathbf{X}</span> je matice
        zadaných hodnot vysvětlujících proměnných o rozměrech <span
        class="math inline">n \times k</span></p></li>
        <li><p><span
        class="math inline">\overset{\underline{}}{\beta}</span> je
        vektor <span class="math inline">p = k</span> neznámých
        parametrů</p></li>
        <li><p><span
        class="math inline">\overset{\underline{}}{e}</span> je vektor
        <span class="math inline">n</span> hodnot náhodných
        chyb</p></li>
        </ul>
        <p>Předpoklady obecného lineárního modelu</p>
        <ol type="1">
        <li><p><span class="math inline">\forall i \leq n:Ee_{i} =
        0</span><br />
        náhodná složka nepůsobí systematickým způsobem na hodnoty
        vysvětlované proměnné <span
        class="math inline">Y</span></p></li>
        <li><p><span class="math inline">\forall i \leq n:De_{i} =
        \sigma^{2}</span><br />
        homoskedasticita náhodných složek, variabilita náhodné složky
        nezávisí na hodnotách vysvětlujících proměnných</p></li>
        <li><p><span class="math inline">\forall i,j \leq n;i \neq
        j:Cov\left( e_{i},e_{j} \right) = 0</span><br />
        náhodné složky jsou nekorelované</p></li>
        <li><p><span class="math inline">\mathbf{X}</span> je
        nestochastická matice.</p></li>
        <li><p>Parametry <span class="math inline">\beta_{j},j \leq
        k</span> nabývají libovolných hodnot.</p></li>
        </ol>
        <p>Pokud platí předpoklady 6 a 7, nazýváme model
        <strong>regresní model</strong>.</p>
        <ol start="6" type="1">
        <li><p><span class="math inline">h\left( \mathbf{X} \right) = k
        \land n &gt; k</span><br />
        mezi vysvětlujícími proměnnými nebyla funkční lineární
        závislost</p></li>
        <li><p><span class="math inline">\forall i \leq n:e_{i} \sim
        N</span><br />
        toto také implikuje normalitu proměnné <span
        class="math inline">Y</span></p></li>
        </ol>
        <p>Mezi několik regresních modelů patří:</p>
        <ul>
        <li><p>Obecná regresní přímka, nebo lineární regrese s jednou
        vysvětlující proměnnou<br />
        <span class="math display">Y_{i} = \beta_{0} + \beta_{i}x_{i} +
        e_{i},X = \begin{pmatrix}
        1 &amp; x_{i} \\
        \cdots &amp; \cdots \\
        1 &amp; x_{n}
        \end{pmatrix},\overset{\underline{}}{\beta} = \begin{pmatrix}
        \beta_{0} \\
        \beta_{1}
        \end{pmatrix}</span></p></li>
        <li><p>Kvadratická regrese<br />
        <span class="math display">Y_{i} = \beta_{0} + \beta_{i}x_{i} +
        \beta_{2}x_{i}^{2} + e_{i}</span></p></li>
        </ul>
        <h2
        id="lineární-regrese-s-jednou-vysvětlující-proměnnou">Lineární
        regrese s jednou vysvětlující proměnnou</h2>
        <p>Mějme <span class="math inline">n &gt; 2</span> pozorování,
        tedy <span class="math inline">n</span> dvojic <span
        class="math inline">\left( Y_{i},x_{i} \right)</span>, ze
        kterých sestavíme model <span class="math inline">Y_{i} =
        \beta_{0} + \beta_{i}x_{i} + e_{i}</span>. Pro jeho určení
        využijeme metody nejmenších čtverců, tj. <span
        class="math inline">\min{\sum_{i = 1}^{n}e_{i}^{2}}</span>. Toto
        vede na soustavu normálních rovnic vedoucí k řešení <span
        class="math inline">b_{1} = \frac{\sum_{i = 1}^{n}{\left( x_{i}
        - \overline{x} \right)Y_{i}}}{\sum_{i = 1}^{n}\left( x_{i} -
        \overline{x} \right)^{2}}</span> a <span
        class="math inline">b_{0} = \overline{Y} -
        b_{1}\overline{x}</span>. Odhadem hodnoty <span
        class="math inline">E\left( Y \middle| x \right)</span> je poté
        statistika <span class="math inline">\widehat{Y}(x) = b_{0} +
        b_{1}x</span>. Jako vektor <strong>reziduí</strong> považujeme
        <span class="math inline">\widehat{e_{i}} = Y_{i} -
        \widehat{Y_{i}}</span>.</p>
        <p>Pro hledání intervalového odhadu pro <span
        class="math inline">E\left( Y \middle| x \right)</span> budeme
        vycházet ze statistiky <span
        class="math inline">\frac{\widehat{Y}(x) - \beta_{0} -
        \beta_{1}x}{S_{\widehat{Y}}} \sim t_{n - 2}</span>.</p>
      </main>

            <nav class="sidebar" id="TOC">
        <h2>Obsah</h2>
        <ul>
        <li><a href="#explorační-analýza-dat"
        id="toc-explorační-analýza-dat">Explorační analýza dat</a></li>
        <li><a href="#teorie-pravděpodobnosti"
        id="toc-teorie-pravděpodobnosti">Teorie
        pravděpodobnosti</a></li>
        <li><a href="#náhodná-veličina"
        id="toc-náhodná-veličina">Náhodná veličina</a>
        <ul>
        <li><a href="#číselné-charakteristiky-náhodné-veličiny"
        id="toc-číselné-charakteristiky-náhodné-veličiny">Číselné
        charakteristiky náhodné veličiny</a></li>
        </ul></li>
        <li><a href="#náhodný-vektor" id="toc-náhodný-vektor">Náhodný
        vektor</a>
        <ul>
        <li><a href="#charakteristiky-náhodného-vektoru"
        id="toc-charakteristiky-náhodného-vektoru">Charakteristiky
        náhodného vektoru</a></li>
        </ul></li>
        <li><a href="#diskrétní-rozdělení-pravděpodobnosti"
        id="toc-diskrétní-rozdělení-pravděpodobnosti">Diskrétní
        rozdělení pravděpodobnosti</a>
        <ul>
        <li><a href="#hypergeometrická-náhodná-veličina"
        id="toc-hypergeometrická-náhodná-veličina">Hypergeometrická
        náhodná veličina</a></li>
        <li><a href="#binomická-náhodná-veličina"
        id="toc-binomická-náhodná-veličina">Binomická náhodná
        veličina</a></li>
        <li><a href="#geometrická-náhodná-veličina"
        id="toc-geometrická-náhodná-veličina">Geometrická náhodná
        veličina</a></li>
        <li><a href="#negativně-binomická-náhodná-veličina"
        id="toc-negativně-binomická-náhodná-veličina">Negativně
        binomická náhodná veličina</a></li>
        <li><a href="#poissonovo-rozdělení-pravděpodobnosti"
        id="toc-poissonovo-rozdělení-pravděpodobnosti">Poissonovo
        rozdělení pravděpodobnosti</a></li>
        </ul></li>
        <li><a href="#spojitá-rozdělení-pravděpodobnosti"
        id="toc-spojitá-rozdělení-pravděpodobnosti">Spojitá rozdělení
        pravděpodobnosti</a>
        <ul>
        <li><a href="#rovnoměrné-rozložení"
        id="toc-rovnoměrné-rozložení">Rovnoměrné rozložení</a></li>
        <li><a href="#exponenciální-rozdělení"
        id="toc-exponenciální-rozdělení">Exponenciální
        rozdělení</a></li>
        <li><a href="#erlangovo-rozdělení"
        id="toc-erlangovo-rozdělení">Erlangovo rozdělení</a></li>
        <li><a href="#weibullovo-rozdělení"
        id="toc-weibullovo-rozdělení">Weibullovo rozdělení</a></li>
        <li><a href="#normální-rozdělení"
        id="toc-normální-rozdělení">Normální rozdělení</a>
        <ul>
        <li><a href="#normované-normální-rozdělení"
        id="toc-normované-normální-rozdělení">Normované normální
        rozdělení</a></li>
        </ul></li>
        <li><a href="#mathbfchimathbf2-rozdělení"
        id="toc-mathbfchimathbf2-rozdělení"><span
        class="math inline">\mathbf{\chi}^{\mathbf{2}}</span>
        rozdělení</a></li>
        <li><a href="#studentovo-rozdělení"
        id="toc-studentovo-rozdělení">Studentovo rozdělení</a></li>
        <li><a href="#fisherovo-snedecorovo-rozdělení"
        id="toc-fisherovo-snedecorovo-rozdělení">Fisherovo-Snedecorovo
        rozdělení</a></li>
        </ul></li>
        <li><a href="#limitní-věty" id="toc-limitní-věty">Limitní
        věty</a>
        <ul>
        <li><a href="#centrální-limitní-věta"
        id="toc-centrální-limitní-věta">Centrální limitní věta</a></li>
        </ul></li>
        <li><a href="#náhodné-výběry-a-jejich-zpracování"
        id="toc-náhodné-výběry-a-jejich-zpracování">Náhodné výběry a
        jejich zpracování</a>
        <ul>
        <li><a href="#teorie-odhadu" id="toc-teorie-odhadu">Teorie
        odhadu</a>
        <ul>
        <li><a href="#intervalový-odhad"
        id="toc-intervalový-odhad">Intervalový odhad</a></li>
        </ul></li>
        <li><a href="#testování-hypotéz"
        id="toc-testování-hypotéz">Testování hypotéz</a></li>
        <li><a href="#anova-analýza-rozptylu"
        id="toc-anova-analýza-rozptylu">ANOVA Analýza rozptylu</a></li>
        </ul></li>
        <li><a href="#regresní-analýza"
        id="toc-regresní-analýza">Regresní analýza</a>
        <ul>
        <li><a href="#obecný-lineární-model"
        id="toc-obecný-lineární-model">Obecný lineární model</a></li>
        <li><a href="#lineární-regrese-s-jednou-vysvětlující-proměnnou"
        id="toc-lineární-regrese-s-jednou-vysvětlující-proměnnou">Lineární
        regrese s jednou vysvětlující proměnnou</a></li>
        </ul></li>
        </ul>
      </nav>
          </div>
  </body>
</html>
